{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd                 # dataframe storing\n",
    "from bs4 import BeautifulSoup       # parsing web content in a nice way\n",
    "import ssl                          # MAY BE UNNECESSARY: provides access to the security socket layer (ssl) https://docs.python.org/3/library/ssl.html\n",
    "import urllib                       # open and navigate URL's\n",
    "import os\n",
    "\n",
    "from selenium import webdriver      # load and run the webpage dynamically.\n",
    "# from selenium.webdriver.chrome.options import Options\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a autonomous Chrome page to dynamically load the page for scraping. \n",
    "# Requires webdriver to be downloaded and then its path directed to.\n",
    "\n",
    "# # iniate \"headless\" which stops chrome from showing itself when this is run\n",
    "# options = Options()\n",
    "# options.headless = True\n",
    "\n",
    "\n",
    "# Unless you want to change to location, make sure the chromedriver program is located within the same file folder that you run this application in.\n",
    "# You must have chrome (or a chromium base like internet explorer). Download software here: https://chromedriver.chromium.org/downloads\n",
    "path = os.getcwd() + \"/chromedriver\"\n",
    "driver = webdriver.Chrome(executable_path = path)\n",
    "# driver.maximize_window()\n",
    "\n",
    "\n",
    "homeURL = \"https://ehrafworldcultures.yale.edu/\"\n",
    "searchTokens = \"/search?q=text%3AApple&fq=culture_level_samples%7CPSF\"\n",
    "\n",
    "# Load the HTML page (note that this should be updated to allow for modular input)\n",
    "driver.get(homeURL + searchTokens)\n",
    "\n",
    "# Find then click on each tab to reveal content for scraping\n",
    "# Elements must be individually clicked backwards. I do not know why this is a thing but my guess is each \n",
    "# clicked tab adds HTML pushing future tabs to a new location thereby making some indexing no longer point to a retrieved tab. \n",
    "# Loading backwards avoids this.\n",
    "country_tab = driver.find_elements_by_class_name('trad-overview__result')\n",
    "for i in range(len(country_tab)-1,-1,-1):\n",
    "    try:\n",
    "        #Note: this clicking should work for each of the continents. However, technically, trad-overview__result is not the actual \n",
    "        # element that should be clicked on. It is just good enough for simplicity sake. If this give you trouble, consider putting in\n",
    "        # driver.execute_script(\"arguments[0].click();\", country_tab[doc_i]) and changing the above drive.find to a button element or whatever is the true clickable drop down, \n",
    "        # although this will take a bit more indexing so beware.\n",
    "        country_tab[i].click()\n",
    "        \n",
    "        \n",
    "    except:\n",
    "        print(f\"WARNING tab {i} failed to be clicked\")\n",
    "\n",
    "# Parse processed webpage with BeautifulSoup\n",
    "soup = BeautifulSoup(driver.page_source)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Africa\n",
      "Asia\n",
      "Europe\n",
      "Middle America and the Caribbean\n",
      "Middle East\n",
      "North America\n",
      "Oceania\n",
      "South America\n"
     ]
    }
   ],
   "source": [
    "#Example of finding then printing out the dynamic webpage (before clicking). Shown here are the continents\n",
    "continent_dir = soup.find_all('div',\n",
    "{'class':'trad-overview__result'})\n",
    "\n",
    "for x in continent_dir:\n",
    "    print(x.h4.button.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cultures extracted 48\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary to store all cultures and their links for later use\n",
    "culture_dict = {}\n",
    "\n",
    "# find the tables containing the cultures then loop through them to extract their subregion, continent, name, and the link to the passages\n",
    "# Note that if the ehraf website changes, this loop might need fixing by changing where the information is retrieved.\n",
    "# Also note that if the dynamic page is not loaded correctly, (a warning is given above), this may also fail.\n",
    "table_culture_links = soup.find_all('tr', {'class':'mdc-data-table__row'})\n",
    "for culture_i in table_culture_links:\n",
    "    culture_list = list(culture_i.children)\n",
    "\n",
    "    subRegion = culture_list[0].text\n",
    "    cultureName = culture_list[1].a.text\n",
    "    link = culture_list[1].a.attrs['href']\n",
    "    continent = culture_i.findParent('table', {'role':'region'}).attrs['id']\n",
    "    # \n",
    "    culture_dict[cultureName] = {\"Continent\":continent, \"SubRegion\":subRegion, \"link\":link}\n",
    "print(f\"Number of cultures extracted {len(culture_dict)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "WARNING docTab 4 failed to be clicked\n",
      "0\n",
      "WARNING docTab 5 failed to be clicked\n",
      "0\n",
      "WARNING docTab 7 failed to be clicked\n",
      "0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/ericchantland/Documents/GitHub/Boyer_eHRAF_Misery/eHRAF_Scraper.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ericchantland/Documents/GitHub/Boyer_eHRAF_Misery/eHRAF_Scraper.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# This will go through every culture and take the passages from every source. \u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ericchantland/Documents/GitHub/Boyer_eHRAF_Misery/eHRAF_Scraper.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# It will then record each passage's text, OCM, and OWC\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ericchantland/Documents/GitHub/Boyer_eHRAF_Misery/eHRAF_Scraper.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m key, val \u001b[39min\u001b[39;00m culture_dict\u001b[39m.\u001b[39mitems():\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ericchantland/Documents/GitHub/Boyer_eHRAF_Misery/eHRAF_Scraper.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39m# navigate to a culture's page via the link\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ericchantland/Documents/GitHub/Boyer_eHRAF_Misery/eHRAF_Scraper.ipynb#W4sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     driver\u001b[39m.\u001b[39;49mget(homeURL \u001b[39m+\u001b[39;49m culture_dict[key][\u001b[39m'\u001b[39;49m\u001b[39mlink\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ericchantland/Documents/GitHub/Boyer_eHRAF_Misery/eHRAF_Scraper.ipynb#W4sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39m#click through the source tabs\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ericchantland/Documents/GitHub/Boyer_eHRAF_Misery/eHRAF_Scraper.ipynb#W4sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     sourceTab \u001b[39m=\u001b[39m driver\u001b[39m.\u001b[39mfind_elements_by_class_name(\u001b[39m'\u001b[39m\u001b[39mmdc-data-table__row\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/eHRAF_Scraper/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py:333\u001b[0m, in \u001b[0;36mWebDriver.get\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(\u001b[39mself\u001b[39m, url):\n\u001b[1;32m    330\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    331\u001b[0m \u001b[39m    Loads a web page in the current browser session.\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 333\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexecute(Command\u001b[39m.\u001b[39;49mGET, {\u001b[39m'\u001b[39;49m\u001b[39murl\u001b[39;49m\u001b[39m'\u001b[39;49m: url})\n",
      "File \u001b[0;32m/opt/anaconda3/envs/eHRAF_Scraper/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py:319\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    316\u001b[0m         params[\u001b[39m'\u001b[39m\u001b[39msessionId\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msession_id\n\u001b[1;32m    318\u001b[0m params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wrap_value(params)\n\u001b[0;32m--> 319\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcommand_executor\u001b[39m.\u001b[39;49mexecute(driver_command, params)\n\u001b[1;32m    320\u001b[0m \u001b[39mif\u001b[39;00m response:\n\u001b[1;32m    321\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39merror_handler\u001b[39m.\u001b[39mcheck_response(response)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/eHRAF_Scraper/lib/python3.10/site-packages/selenium/webdriver/remote/remote_connection.py:374\u001b[0m, in \u001b[0;36mRemoteConnection.execute\u001b[0;34m(self, command, params)\u001b[0m\n\u001b[1;32m    372\u001b[0m data \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39mdump_json(params)\n\u001b[1;32m    373\u001b[0m url \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_url, path)\n\u001b[0;32m--> 374\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(command_info[\u001b[39m0\u001b[39;49m], url, body\u001b[39m=\u001b[39;49mdata)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/eHRAF_Scraper/lib/python3.10/site-packages/selenium/webdriver/remote/remote_connection.py:397\u001b[0m, in \u001b[0;36mRemoteConnection._request\u001b[0;34m(self, method, url, body)\u001b[0m\n\u001b[1;32m    394\u001b[0m     body \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    396\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkeep_alive:\n\u001b[0;32m--> 397\u001b[0m     resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conn\u001b[39m.\u001b[39;49mrequest(method, url, body\u001b[39m=\u001b[39;49mbody, headers\u001b[39m=\u001b[39;49mheaders)\n\u001b[1;32m    399\u001b[0m     statuscode \u001b[39m=\u001b[39m resp\u001b[39m.\u001b[39mstatus\n\u001b[1;32m    400\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/eHRAF_Scraper/lib/python3.10/site-packages/urllib3/request.py:78\u001b[0m, in \u001b[0;36mRequestMethods.request\u001b[0;34m(self, method, url, fields, headers, **urlopen_kw)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_encode_url(\n\u001b[1;32m     75\u001b[0m         method, url, fields\u001b[39m=\u001b[39mfields, headers\u001b[39m=\u001b[39mheaders, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39murlopen_kw\n\u001b[1;32m     76\u001b[0m     )\n\u001b[1;32m     77\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 78\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest_encode_body(\n\u001b[1;32m     79\u001b[0m         method, url, fields\u001b[39m=\u001b[39;49mfields, headers\u001b[39m=\u001b[39;49mheaders, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49murlopen_kw\n\u001b[1;32m     80\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/eHRAF_Scraper/lib/python3.10/site-packages/urllib3/request.py:170\u001b[0m, in \u001b[0;36mRequestMethods.request_encode_body\u001b[0;34m(self, method, url, fields, headers, encode_multipart, multipart_boundary, **urlopen_kw)\u001b[0m\n\u001b[1;32m    167\u001b[0m extra_kw[\u001b[39m\"\u001b[39m\u001b[39mheaders\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mupdate(headers)\n\u001b[1;32m    168\u001b[0m extra_kw\u001b[39m.\u001b[39mupdate(urlopen_kw)\n\u001b[0;32m--> 170\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49murlopen(method, url, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mextra_kw)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/eHRAF_Scraper/lib/python3.10/site-packages/urllib3/poolmanager.py:376\u001b[0m, in \u001b[0;36mPoolManager.urlopen\u001b[0;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[1;32m    374\u001b[0m     response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39murlopen(method, url, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw)\n\u001b[1;32m    375\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 376\u001b[0m     response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(method, u\u001b[39m.\u001b[39;49mrequest_uri, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n\u001b[1;32m    378\u001b[0m redirect_location \u001b[39m=\u001b[39m redirect \u001b[39mand\u001b[39;00m response\u001b[39m.\u001b[39mget_redirect_location()\n\u001b[1;32m    379\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m redirect_location:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/eHRAF_Scraper/lib/python3.10/site-packages/urllib3/connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    702\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    704\u001b[0m     conn,\n\u001b[1;32m    705\u001b[0m     method,\n\u001b[1;32m    706\u001b[0m     url,\n\u001b[1;32m    707\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    708\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    709\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    710\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    711\u001b[0m )\n\u001b[1;32m    713\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    714\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    715\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    716\u001b[0m \u001b[39m# mess.\u001b[39;00m\n\u001b[1;32m    717\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/eHRAF_Scraper/lib/python3.10/site-packages/urllib3/connectionpool.py:449\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    444\u001b[0m             httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39mgetresponse()\n\u001b[1;32m    445\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m             \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m             \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m             \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m--> 449\u001b[0m             six\u001b[39m.\u001b[39;49mraise_from(e, \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    450\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    451\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/eHRAF_Scraper/lib/python3.10/site-packages/urllib3/connectionpool.py:444\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    442\u001b[0m     \u001b[39m# Python 3\u001b[39;00m\n\u001b[1;32m    443\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 444\u001b[0m         httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[1;32m    445\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m         \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m         \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m         \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m    449\u001b[0m         six\u001b[39m.\u001b[39mraise_from(e, \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/eHRAF_Scraper/lib/python3.10/http/client.py:1374\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1372\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1373\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1374\u001b[0m         response\u001b[39m.\u001b[39;49mbegin()\n\u001b[1;32m   1375\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n\u001b[1;32m   1376\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/eHRAF_Scraper/lib/python3.10/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[39m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/eHRAF_Scraper/lib/python3.10/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_status\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadline(_MAXLINE \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m), \u001b[39m\"\u001b[39m\u001b[39miso-8859-1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(line) \u001b[39m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[39mraise\u001b[39;00m LineTooLong(\u001b[39m\"\u001b[39m\u001b[39mstatus line\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/eHRAF_Scraper/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    706\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# This will go through every culture and take the passages from every source. \n",
    "# It will then record each passage's text, OCM, and OWC\n",
    "for key, val in culture_dict.items():\n",
    "    # navigate to a culture's page via the link\n",
    "    driver.get(homeURL + culture_dict[key]['link'])\n",
    "\n",
    "    \n",
    "    #click through the source tabs\n",
    "    sourceTab = driver.find_elements_by_class_name('mdc-data-table__row')\n",
    "    for sourceTab_i in range(len(sourceTab)-1,-1,-1):\n",
    "        try:\n",
    "            sourceTab[sourceTab_i].click()\n",
    "        except:\n",
    "            print(f\"WARNING sourceTab {sourceTab_i} failed to be clicked\")\n",
    "    \n",
    "    # Load the webpage to be parsed\n",
    "    soup = BeautifulSoup(driver.page_source)\n",
    "    \n",
    "    #Log the source table's results number in order to know where to start and stop clicking.\n",
    "    # Skip every 2 logs as they do not contain the information desired\n",
    "    sourceCount = soup.find_all('td',{'class':'mdc-data-table__cell mdc-data-table__cell--numeric'})\n",
    "    sourceCount_list = list(map(lambda x: int(x.text), sourceCount[0::3]))\n",
    "\n",
    "    #go through each source\n",
    "    # pastTabs is to help with indexing so the clicker does not click tabs already clicked\n",
    "    pastTabs = 0\n",
    "    for source_i in sourceCount_list:\n",
    "        total = source_i #superfluous?\n",
    "        while total > 0:\n",
    "            #mark out the number of tabs to be clicked (as the driver does not know when to stop clicking)\n",
    "            if total >= 10:\n",
    "                log = 10\n",
    "            else:\n",
    "                log = total\n",
    "            total = total - log     #remove the count from total for tabs about to be recorded\n",
    "\n",
    "            #click through the individual document tabs\n",
    "            # docTab = driver.find_elements_by_class_name('trad-data__results--row')\n",
    "            docTab = driver.find_elements_by_class_name('trad-data__results--row')\n",
    "            \n",
    "            for docTab_i in range(log+pastTabs-1,pastTabs-1,-1):\n",
    "                # driver.implicitly_wait(10)\n",
    "                try:\n",
    "                    docTab[docTab_i].click()\n",
    "                except:\n",
    "                    print(f\"WARNING docTab {docTab_i} failed to be clicked\")           \n",
    "            soup = BeautifulSoup(driver.page_source)\n",
    "            print(total)\n",
    "        pastTabs+=log\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "soup = BeautifulSoup(driver.page_source)\n",
    "#Log the source table's results number in order to know where to start and stop clicking.\n",
    "# Skip every 2 logs as they do not contain the information desired\n",
    "sourceCount = soup.find_all('td',{'class':'mdc-data-table__cell mdc-data-table__cell--numeric'})\n",
    "sourceCount_list = list(map(lambda x: int(x.text), sourceCount[0::3]))\n",
    "print(sourceCount_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "WARNING docTab 6 failed to be clicked\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# This will go through every culture and take the passages from every source. \n",
    "# It will then record each passage's text, OCM, and OWC\n",
    "# for key, val in culture_dict.items():\n",
    "#navigate to a culture's page via the link\n",
    "driver.get(homeURL + culture_dict['Saami']['link'])\n",
    "\n",
    "#click through the source tabs\n",
    "sourceTab = driver.find_elements_by_class_name('mdc-data-table__row')\n",
    "for i in range(len(sourceTab)-1,-1,-1):\n",
    "    try:\n",
    "        sourceTab[i].click()\n",
    "    except:\n",
    "        print(f\"WARNING sourceTab {i} failed to be clicked\")\n",
    "        \n",
    "soup = BeautifulSoup(driver.page_source)\n",
    "#Log the source table's results number in order to know where to start and stop clicking.\n",
    "# Skip every 2 logs as they do not contain the information desired\n",
    "sourceCount = soup.find_all('td',{'class':'mdc-data-table__cell mdc-data-table__cell--numeric'})\n",
    "sourceCount_list = list(map(lambda x: int(x.text), sourceCount[0::3]))\n",
    "\n",
    "#go through each source\n",
    "# pastTabs is to help with indexing so the clicker does not click tabs already clicked\n",
    "pastTabs = 0\n",
    "for source_i in sourceCount_list:\n",
    "    total = source_i #superfluous?\n",
    "    while total > 0:\n",
    "        #mark out the number of tabs to be clicked (as the driver does not know when to stop clicking)\n",
    "        if total >= 10:\n",
    "            log = 10\n",
    "        else:\n",
    "            log = total\n",
    "        total = total - log     #remove the count from total for tabs about to be recorded\n",
    "\n",
    "        #click through the individual document tabs\n",
    "        docTab = driver.find_elements_by_class_name('trad-data__results--row')\n",
    "        for doc_i in range(log+pastTabs-1,pastTabs-1,-1):\n",
    "            try:\n",
    "                docTab[doc_i].click()\n",
    "            except:\n",
    "                print(f\"WARNING docTab {doc_i} failed to be clicked\")\n",
    "        # soup = BeautifulSoup(driver.page_source)\n",
    "        print(total)\n",
    "    pastTabs+=log\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "# driver.get("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "4\n",
      "3\n",
      "2\n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "log = 6\n",
    "pastTabs = 0\n",
    "x = [0,1,2,3,4,5,6,7,8,9,10,11,12,13]\n",
    "for i in range(log+pastTabs-1,pastTabs-1,-1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<td class=\"mdc-data-table__cell mdc-data-table__cell--numeric\">1</td>,\n",
       " <td class=\"mdc-data-table__cell mdc-data-table__cell--numeric\">1926</td>,\n",
       " <td class=\"mdc-data-table__cell mdc-data-table__cell--numeric\">not specified</td>,\n",
       " <td class=\"mdc-data-table__cell mdc-data-table__cell--numeric\">4</td>,\n",
       " <td class=\"mdc-data-table__cell mdc-data-table__cell--numeric\">1937</td>,\n",
       " <td class=\"mdc-data-table__cell mdc-data-table__cell--numeric\">1926-1929</td>,\n",
       " <td class=\"mdc-data-table__cell mdc-data-table__cell--numeric\">1</td>,\n",
       " <td class=\"mdc-data-table__cell mdc-data-table__cell--numeric\">1956</td>,\n",
       " <td class=\"mdc-data-table__cell mdc-data-table__cell--numeric\">not specified</td>,\n",
       " <td class=\"mdc-data-table__cell mdc-data-table__cell--numeric\">2</td>,\n",
       " <td class=\"mdc-data-table__cell mdc-data-table__cell--numeric\">1971</td>,\n",
       " <td class=\"mdc-data-table__cell mdc-data-table__cell--numeric\">ca. 1863 - 1930</td>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_table = soup.find_all('td',{'class':'mdc-data-table__cell--numeric'})\n",
    "source_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "#A way to retrieve the results list\n",
    "source_table = soup.find_all('td',{'class':'mdc-data-table__cell mdc-data-table__cell--numeric'})\n",
    "source_table_list = list(map(lambda x: int(x.text), source_table[0::3]))\n",
    "print(source_table_list)\n",
    "# for i in source_table[0::3]:\n",
    "#     print(i.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dummy example for clicking links ion the next page.\n",
    "driver.get(homeURL + culture_dict['Azande']['link'])\n",
    "sourceTab = driver.find_elements_by_class_name('mdc-data-table__row')\n",
    "for i in range(len(sourceTab)-1,-1,-1):\n",
    "    try:\n",
    "        sourceTab[i].click()\n",
    "    except:\n",
    "        print(f\"WARNING tab {i} failed to be clicked\")\n",
    "        \n",
    "soup = BeautifulSoup(driver.page_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(homeURL + culture_dict['Azande']['link'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"1eeb63906685dccc9e96c7be4121e53d\", element=\"e52c8c44-d05f-4048-b7bd-19e4645e4d80\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"1eeb63906685dccc9e96c7be4121e53d\", element=\"3908a8fb-f2cb-4e38-ade6-637a072040a3\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"1eeb63906685dccc9e96c7be4121e53d\", element=\"6980db78-7e48-4e65-88cb-926f9ca0cace\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"1eeb63906685dccc9e96c7be4121e53d\", element=\"90b49251-6d02-4dbb-a4e9-ab625d722592\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"1eeb63906685dccc9e96c7be4121e53d\", element=\"86ff4a41-da13-4ec5-acc4-b52b44d4a6a9\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"1eeb63906685dccc9e96c7be4121e53d\", element=\"13281286-645b-4ca5-9889-899d1ecf1f3f\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"1eeb63906685dccc9e96c7be4121e53d\", element=\"6051bcac-f673-4fa8-bd1f-f8362fe1598e\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"1eeb63906685dccc9e96c7be4121e53d\", element=\"167d566a-c290-4818-afe8-506a0e74179b\")>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultsTab = driver.find_elements_by_class_name('trad-data__results--row')\n",
    "resultsTab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"1eeb63906685dccc9e96c7be4121e53d\", element=\"e52c8c44-d05f-4048-b7bd-19e4645e4d80\")>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultsTab[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "x = [0,1,2,3,4,5,6,7,8,9,10,11,12,13]\n",
    "print(x[1:11])\n",
    "print(len(x[1:11]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "1 1\n",
      "2 2\n",
      "3 3\n",
      "4 4\n",
      "5 5\n",
      "6 6\n",
      "7 7\n",
      "8 8\n",
      "9 9\n",
      "10 10\n",
      "11 11\n",
      "12 12\n",
      "13 13\n"
     ]
    }
   ],
   "source": [
    "x = [0,1,2,3,4,5,6,7,8,9,10,11,12,13]\n",
    "# x_e = enumerate(x)\n",
    "\n",
    "for i, enu in enumerate(x):\n",
    "    print(i, enu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_table = soup.find_all('tr',{'class':'mdc-data-table__row'})\n",
    "len(document_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import bs4.element as element\n",
    "# body_child_tags = list(filter( lambda x: type(x) == element.Tag, country_links)) #go through, if there are tags, create a list then print\n",
    "# body_child_tags "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "    8\n",
      "    7\n",
      "1\n",
      "    6\n",
      "1\n",
      "    5\n",
      "4\n",
      "    4\n",
      "    3\n",
      "    2\n",
      "    1\n"
     ]
    }
   ],
   "source": [
    "docTab = [1,2,3,4,5,6,7,8]\n",
    "pastTabs = 0\n",
    "sourceCount_list = [4,1,1,2]\n",
    "for i in range(len(sourceCount_list)-1,-1,-1):\n",
    "    log = sourceCount_list[i]\n",
    "    print(log)\n",
    "    for ii in range(len(docTab)-pastTabs-1, len(docTab)-log-pastTabs-1,-1):\n",
    "        print(f\"    {docTab[ii]}\")\n",
    "    pastTabs += log\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# driver.get(homeURL + culture_dict['Azande']['link'])\n",
    "\n",
    "driver.get(homeURL + culture_dict['Serbs']['link'])\n",
    "\n",
    "soup = BeautifulSoup(driver.page_source)\n",
    "\n",
    "#Log the source table's results number in order to know where to start and stop clicking.\n",
    "# Skip every 2 logs as they do not contain the information desired\n",
    "sourceCount = soup.find_all('td',{'class':'mdc-data-table__cell mdc-data-table__cell--numeric'})\n",
    "sourceCount_list = list(map(lambda x: int(x.text), sourceCount[0::3]))\n",
    "\n",
    "\n",
    "sourceTabs = driver.find_elements_by_class_name('mdc-data-table__row')\n",
    "for i in range(len(sourceTabs)-1,-1,-1):\n",
    "    try:\n",
    "        driver.execute_script(\"arguments[0].click();\", sourceTabs[i])\n",
    "        # sourceTabs[i].click()\n",
    "    except:\n",
    "        print(f\"WARNING sourceTab {i} failed to be clicked\")\n",
    "# wait so the page can be loaded\n",
    "time.sleep(.5)\n",
    "#get the results tab for sub indexing sources\n",
    "resultsTabs = driver.find_elements_by_class_name('trad-data__results')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#go through each source tab and click on it then extract desired information\n",
    "for sourceTab_i in range(len(resultsTabs)-1,-1,-1):\n",
    "    \n",
    "    #Find the individual source tab for clicking\n",
    "    sourceTab = resultsTabs[sourceTab_i]\n",
    "    docTab = sourceTab.find_elements_by_class_name('sre-result__title')\n",
    "    for doc_i in range(len(docTab)-1,-1,-1):\n",
    "        try:\n",
    "            # unfortunately, clicking on the script normally produces errors where some tabs are not revealed. Must run through javascript function\n",
    "            driver.execute_script(\"arguments[0].click();\", docTab[doc_i])\n",
    "            # docTab[doc_i].click()\n",
    "        except:\n",
    "            print(f\"WARNING docTab {doc_i} in failed to be clicked\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "#Erase\n",
    "DEBUG_count = 0\n",
    "\n",
    "# driver.get(homeURL + culture_dict['Azande']['link'])\n",
    "driver.get(homeURL + culture_dict['Serbs']['link'])\n",
    "\n",
    "soup = BeautifulSoup(driver.page_source)\n",
    "#Log the source table's results number in order to know where to start and stop clicking.\n",
    "# Skip every 2 logs as they do not contain the information desired\n",
    "sourceCount = soup.find_all('td',{'class':'mdc-data-table__cell mdc-data-table__cell--numeric'})\n",
    "sourceCount_list = list(map(lambda x: int(x.text), sourceCount[0::3]))\n",
    "\n",
    "#Click every source tab\n",
    "sourceTabs = driver.find_elements_by_class_name('mdc-data-table__row')\n",
    "for source_i in sourceTabs:\n",
    "    driver.execute_script(\"arguments[0].click();\", source_i)\n",
    "\n",
    "# wait to make sure the page is loaded. CHANGE to a higher time if it runs indefinately\n",
    "time.sleep(.1)\n",
    "#get the results tab(which is basically the source tab but contained within a different HTML element) for sub indexing sources\n",
    "\n",
    "resultsTabs = driver.find_elements_by_class_name('trad-data__results')\n",
    "for i in range(len(resultsTabs)):\n",
    "    total = sourceCount_list[i]\n",
    "    \n",
    "    #While total is > 0\n",
    "    while True:\n",
    "        docTabs = resultsTabs[i].find_elements_by_class_name('sre-result__title')\n",
    "        for doc_i in docTabs:\n",
    "            driver.execute_script(\"arguments[0].click();\", doc_i)\n",
    "            #####Now get the info from the tab######\n",
    "            #CODE HERE\n",
    "            DEBUG_count +=1\n",
    "        \n",
    "        total -= len(docTabs)\n",
    "        # If there are more tabs hidden away, find the button, click it, and then refresh the results\n",
    "        # otherwise, end the loop\n",
    "        if total >0:\n",
    "            SourceTabFooter = resultsTabs[i].find_elements_by_class_name('trad-data__results--pagination')\n",
    "            buttons = SourceTabFooter[0].find_elements_by_class_name('rmwc-icon--ligature')\n",
    "            driver.execute_script(\"arguments[0].click();\", buttons[-1])\n",
    "            time.sleep(.1)\n",
    "            resultsTabs = driver.find_elements_by_class_name('trad-data__results')\n",
    "        else:\n",
    "            break\n",
    "        if DEBUG_count > sum(sourceCount_list):\n",
    "            print(ValueError)\n",
    "            break\n",
    "    \n",
    "             \n",
    "print(DEBUG_count)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "element = WebDriverWait(driver, 10).until(EC.presence_of_all_elements_located(By.CLASS_NAME,  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = driver.find_elements_by_class_name('sre-result__sre-content')\n",
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = driver.find_elements_by_class_name('trad-data__results--footer')\n",
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/ericchantland/Documents/GitHub/Boyer_eHRAF_Misery/eHRAF_Scraper.ipynb Cell 23\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ericchantland/Documents/GitHub/Boyer_eHRAF_Misery/eHRAF_Scraper.ipynb#X34sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m x \u001b[39m=\u001b[39m driver\u001b[39m.\u001b[39;49mfind_elements_by_class_name(\u001b[39m'\u001b[39;49m\u001b[39mtrad-data__results--pagination\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ericchantland/Documents/GitHub/Boyer_eHRAF_Misery/eHRAF_Scraper.ipynb#X34sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m y \u001b[39m=\u001b[39m x[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mfind_elements_by_class_name(\u001b[39m'\u001b[39m\u001b[39mrmwc-icon--ligature\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ericchantland/Documents/GitHub/Boyer_eHRAF_Misery/eHRAF_Scraper.ipynb#X34sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# y = x[0].find_elements_by_tag_name('button')\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/eHRAF_Scraper/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py:580\u001b[0m, in \u001b[0;36mWebDriver.find_elements_by_class_name\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfind_elements_by_class_name\u001b[39m(\u001b[39mself\u001b[39m, name):\n\u001b[1;32m    567\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    568\u001b[0m \u001b[39m    Finds elements by class name.\u001b[39;00m\n\u001b[1;32m    569\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[39m        elements = driver.find_elements_by_class_name('foo')\u001b[39;00m\n\u001b[1;32m    579\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 580\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfind_elements(by\u001b[39m=\u001b[39;49mBy\u001b[39m.\u001b[39;49mCLASS_NAME, value\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/eHRAF_Scraper/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py:1005\u001b[0m, in \u001b[0;36mWebDriver.find_elements\u001b[0;34m(self, by, value)\u001b[0m\n\u001b[1;32m   1001\u001b[0m         value \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m[name=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m value\n\u001b[1;32m   1003\u001b[0m \u001b[39m# Return empty list if driver returns null\u001b[39;00m\n\u001b[1;32m   1004\u001b[0m \u001b[39m# See https://github.com/SeleniumHQ/selenium/issues/4555\u001b[39;00m\n\u001b[0;32m-> 1005\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexecute(Command\u001b[39m.\u001b[39;49mFIND_ELEMENTS, {\n\u001b[1;32m   1006\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39musing\u001b[39;49m\u001b[39m'\u001b[39;49m: by,\n\u001b[1;32m   1007\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39mvalue\u001b[39;49m\u001b[39m'\u001b[39;49m: value})[\u001b[39m'\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mor\u001b[39;00m []\n",
      "File \u001b[0;32m/opt/anaconda3/envs/eHRAF_Scraper/lib/python3.10/site-packages/selenium/webdriver/remote/webdriver.py:319\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    316\u001b[0m         params[\u001b[39m'\u001b[39m\u001b[39msessionId\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msession_id\n\u001b[1;32m    318\u001b[0m params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wrap_value(params)\n\u001b[0;32m--> 319\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcommand_executor\u001b[39m.\u001b[39;49mexecute(driver_command, params)\n\u001b[1;32m    320\u001b[0m \u001b[39mif\u001b[39;00m response:\n\u001b[1;32m    321\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39merror_handler\u001b[39m.\u001b[39mcheck_response(response)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/eHRAF_Scraper/lib/python3.10/site-packages/selenium/webdriver/remote/remote_connection.py:374\u001b[0m, in \u001b[0;36mRemoteConnection.execute\u001b[0;34m(self, command, params)\u001b[0m\n\u001b[1;32m    372\u001b[0m data \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39mdump_json(params)\n\u001b[1;32m    373\u001b[0m url \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_url, path)\n\u001b[0;32m--> 374\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(command_info[\u001b[39m0\u001b[39;49m], url, body\u001b[39m=\u001b[39;49mdata)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/eHRAF_Scraper/lib/python3.10/site-packages/selenium/webdriver/remote/remote_connection.py:397\u001b[0m, in \u001b[0;36mRemoteConnection._request\u001b[0;34m(self, method, url, body)\u001b[0m\n\u001b[1;32m    394\u001b[0m     body \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    396\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkeep_alive:\n\u001b[0;32m--> 397\u001b[0m     resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conn\u001b[39m.\u001b[39;49mrequest(method, url, body\u001b[39m=\u001b[39;49mbody, headers\u001b[39m=\u001b[39;49mheaders)\n\u001b[1;32m    399\u001b[0m     statuscode \u001b[39m=\u001b[39m resp\u001b[39m.\u001b[39mstatus\n\u001b[1;32m    400\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/eHRAF_Scraper/lib/python3.10/site-packages/urllib3/request.py:78\u001b[0m, in \u001b[0;36mRequestMethods.request\u001b[0;34m(self, method, url, fields, headers, **urlopen_kw)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_encode_url(\n\u001b[1;32m     75\u001b[0m         method, url, fields\u001b[39m=\u001b[39mfields, headers\u001b[39m=\u001b[39mheaders, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39murlopen_kw\n\u001b[1;32m     76\u001b[0m     )\n\u001b[1;32m     77\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 78\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest_encode_body(\n\u001b[1;32m     79\u001b[0m         method, url, fields\u001b[39m=\u001b[39;49mfields, headers\u001b[39m=\u001b[39;49mheaders, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49murlopen_kw\n\u001b[1;32m     80\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/eHRAF_Scraper/lib/python3.10/site-packages/urllib3/request.py:170\u001b[0m, in \u001b[0;36mRequestMethods.request_encode_body\u001b[0;34m(self, method, url, fields, headers, encode_multipart, multipart_boundary, **urlopen_kw)\u001b[0m\n\u001b[1;32m    167\u001b[0m extra_kw[\u001b[39m\"\u001b[39m\u001b[39mheaders\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mupdate(headers)\n\u001b[1;32m    168\u001b[0m extra_kw\u001b[39m.\u001b[39mupdate(urlopen_kw)\n\u001b[0;32m--> 170\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49murlopen(method, url, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mextra_kw)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/eHRAF_Scraper/lib/python3.10/site-packages/urllib3/poolmanager.py:376\u001b[0m, in \u001b[0;36mPoolManager.urlopen\u001b[0;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[1;32m    374\u001b[0m     response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39murlopen(method, url, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw)\n\u001b[1;32m    375\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 376\u001b[0m     response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(method, u\u001b[39m.\u001b[39;49mrequest_uri, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n\u001b[1;32m    378\u001b[0m redirect_location \u001b[39m=\u001b[39m redirect \u001b[39mand\u001b[39;00m response\u001b[39m.\u001b[39mget_redirect_location()\n\u001b[1;32m    379\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m redirect_location:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/eHRAF_Scraper/lib/python3.10/site-packages/urllib3/connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    702\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    704\u001b[0m     conn,\n\u001b[1;32m    705\u001b[0m     method,\n\u001b[1;32m    706\u001b[0m     url,\n\u001b[1;32m    707\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    708\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    709\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    710\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    711\u001b[0m )\n\u001b[1;32m    713\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    714\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    715\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    716\u001b[0m \u001b[39m# mess.\u001b[39;00m\n\u001b[1;32m    717\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/eHRAF_Scraper/lib/python3.10/site-packages/urllib3/connectionpool.py:449\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    444\u001b[0m             httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39mgetresponse()\n\u001b[1;32m    445\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m             \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m             \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m             \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m--> 449\u001b[0m             six\u001b[39m.\u001b[39;49mraise_from(e, \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    450\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    451\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/eHRAF_Scraper/lib/python3.10/site-packages/urllib3/connectionpool.py:444\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    442\u001b[0m     \u001b[39m# Python 3\u001b[39;00m\n\u001b[1;32m    443\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 444\u001b[0m         httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[1;32m    445\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    446\u001b[0m         \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m         \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    448\u001b[0m         \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m    449\u001b[0m         six\u001b[39m.\u001b[39mraise_from(e, \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/eHRAF_Scraper/lib/python3.10/http/client.py:1374\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1372\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1373\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1374\u001b[0m         response\u001b[39m.\u001b[39;49mbegin()\n\u001b[1;32m   1375\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n\u001b[1;32m   1376\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/eHRAF_Scraper/lib/python3.10/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[39m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/eHRAF_Scraper/lib/python3.10/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_status\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadline(_MAXLINE \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m), \u001b[39m\"\u001b[39m\u001b[39miso-8859-1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(line) \u001b[39m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[39mraise\u001b[39;00m LineTooLong(\u001b[39m\"\u001b[39m\u001b[39mstatus line\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/eHRAF_Scraper/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    706\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "x = driver.find_elements_by_class_name('trad-data__results--pagination')\n",
    "y = x[0].find_elements_by_class_name('rmwc-icon--ligature')\n",
    "# y = x[0].find_elements_by_tag_name('button')\n",
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mdc-ripple-upgraded mdc-button mdc-button--dense\n",
    "rmwc-icon rmwc-icon--ligature material-icons mdc-button__icon"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3394e5ff5e37174aec0305e0ed7ec30b336f01a56a90646f493ecbcd8deec75b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
